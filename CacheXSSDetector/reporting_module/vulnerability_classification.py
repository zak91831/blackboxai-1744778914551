"""
Vulnerability Classification Module

This module classifies detected XSS vulnerabilities based on their characteristics,
severity, and exploitation potential, with a focus on cache-based aspects.
"""

import logging
from typing import Dict, List, Optional, Set, Tuple
import json
from datetime import datetime

class VulnerabilityClassifier:
    """
    A class to classify XSS vulnerabilities with focus on cache-based aspects.
    """
    
    def __init__(self, config):
        """
        Initialize the Vulnerability Classifier.
        
        Args:
            config (dict): Configuration settings for vulnerability classification.
        """
        self.logger = logging.getLogger('cachexssdetector.vulnerability_classifier')
        self.config = config
        
        # Classification thresholds
        self.severity_thresholds = {
            'critical': 0.8,
            'high': 0.6,
            'medium': 0.4,
            'low': 0.2
        }
        
        # Initialize classification criteria
        self._init_classification_criteria()
        
        self.logger.info("Vulnerability Classifier initialized")
    
    def _init_classification_criteria(self):
        """Initialize classification criteria and scoring weights."""
        # Vulnerability types
        self.vulnerability_types = {
            'stored_xss': {
                'description': 'XSS payload persists in cache and affects multiple users',
                'severity_multiplier': 1.5,
                'indicators': ['cache_persistence', 'multiple_victims']
            },
            'reflected_xss': {
                'description': 'XSS payload reflected immediately in response',
                'severity_multiplier': 1.0,
                'indicators': ['immediate_reflection', 'single_victim']
            },
            'dom_xss': {
                'description': 'XSS executed through DOM manipulation',
                'severity_multiplier': 1.2,
                'indicators': ['dom_manipulation', 'client_side_execution']
            },
            'cache_poisoning': {
                'description': 'Cache poisoned with malicious content',
                'severity_multiplier': 1.4,
                'indicators': ['cache_control_manipulation', 'shared_cache']
            }
        }
        
        # Impact factors
        self.impact_factors = {
            'authentication_bypass': 1.5,
            'data_exposure': 1.4,
            'functionality_disruption': 1.3,
            'information_theft': 1.4,
            'stored_payload': 1.3,
            'multiple_victims': 1.3,
            'automated_exploitation': 1.2
        }
        
        # Exploitation factors
        self.exploitation_factors = {
            'no_encoding': 1.3,
            'no_filtering': 1.4,
            'executable_context': 1.5,
            'cache_persistence': 1.3,
            'shared_cache': 1.2,
            'predictable_cache': 1.2
        }
        
        # Cache-specific factors
        self.cache_factors = {
            'cache_hit_rate': 1.3,
            'cache_duration': 1.2,
            'cache_scope': 1.4,
            'cache_key_manipulation': 1.3,
            'cache_poisoning_vector': 1.5
        }
    
    def classify_vulnerability(self, finding: Dict, context: Optional[Dict] = None) -> Dict:
        """
        Classify a vulnerability based on its characteristics.
        
        Args:
            finding (dict): The vulnerability finding to classify.
            context (dict, optional): Additional context information.
            
        Returns:
            dict: Classification results.
        """
        classification = {
            'type': None,
            'severity': None,
            'confidence': 0.0,
            'impact_score': 0.0,
            'exploitation_score': 0.0,
            'cache_score': 0.0,
            'overall_score': 0.0,
            'factors': [],
            'recommendations': []
        }
        
        try:
            # Determine vulnerability type
            vuln_type = self._determine_vulnerability_type(finding)
            classification['type'] = vuln_type
            
            # Calculate impact score
            impact_analysis = self._analyze_impact(finding, vuln_type)
            classification['impact_score'] = impact_analysis['score']
            classification['factors'].extend(impact_analysis['factors'])
            
            # Calculate exploitation score
            exploitation_analysis = self._analyze_exploitation(finding)
            classification['exploitation_score'] = exploitation_analysis['score']
            classification['factors'].extend(exploitation_analysis['factors'])
            
            # Calculate cache-specific score
            cache_analysis = self._analyze_cache_factors(finding)
            classification['cache_score'] = cache_analysis['score']
            classification['factors'].extend(cache_analysis['factors'])
            
            # Calculate overall score and severity
            classification.update(
                self._calculate_overall_score(classification)
            )
            
            # Generate recommendations
            classification['recommendations'] = self._generate_recommendations(
                classification,
                finding
            )
            
        except Exception as e:
            self.logger.error(f"Error classifying vulnerability: {str(e)}")
            classification['error'] = str(e)
        
        return classification
    
    def classify_batch(self, findings: List[Dict]) -> List[Dict]:
        """
        Classify a batch of vulnerabilities.
        
        Args:
            findings (list): List of vulnerability findings.
            
        Returns:
            list: Classification results for each finding.
        """
        results = []
        
        # Group findings by URL
        findings_by_url = {}
        for finding in findings:
            url = finding.get('url', '')
            if url:
                if url not in findings_by_url:
                    findings_by_url[url] = []
                findings_by_url[url].append(finding)
        
        # Analyze each group
        for url, url_findings in findings_by_url.items():
            # Analyze patterns across findings
            group_context = self._analyze_group_patterns(url_findings)
            
            # Classify each finding with group context
            for finding in url_findings:
                classification = self.classify_vulnerability(finding, group_context)
                results.append({
                    'finding': finding,
                    'classification': classification,
                    'group_context': group_context
                })
        
        return results
    
    def _determine_vulnerability_type(self, finding: Dict) -> str:
        """
        Determine the type of vulnerability.
        
        Args:
            finding (dict): The finding to analyze.
            
        Returns:
            str: Vulnerability type.
        """
        # Check for cache persistence
        if self._has_cache_persistence(finding):
            if self._is_cache_poisoning(finding):
                return 'cache_poisoning'
            return 'stored_xss'
        
        # Check for DOM-based XSS
        if self._is_dom_based(finding):
            return 'dom_xss'
        
        # Default to reflected XSS
        return 'reflected_xss'
    
    def _analyze_impact(self, finding: Dict, vuln_type: str) -> Dict:
        """
        Analyze the potential impact of the vulnerability.
        
        Args:
            finding (dict): The finding to analyze.
            vuln_type (str): Type of vulnerability.
            
        Returns:
            dict: Impact analysis results.
        """
        analysis = {
            'score': 0.0,
            'factors': []
        }
        
        base_score = 0.5  # Start with medium impact
        
        # Apply type-specific multiplier
        type_info = self.vulnerability_types.get(vuln_type, {})
        multiplier = type_info.get('severity_multiplier', 1.0)
        base_score *= multiplier
        
        # Check impact factors
        for factor, weight in self.impact_factors.items():
            if self._check_impact_factor(finding, factor):
                base_score *= weight
                analysis['factors'].append({
                    'type': 'impact',
                    'name': factor,
                    'weight': weight
                })
        
        analysis['score'] = min(1.0, base_score)
        return analysis
    
    def _analyze_exploitation(self, finding: Dict) -> Dict:
        """
        Analyze exploitation potential.
        
        Args:
            finding (dict): The finding to analyze.
            
        Returns:
            dict: Exploitation analysis results.
        """
        analysis = {
            'score': 0.0,
            'factors': []
        }
        
        base_score = 0.5  # Start with medium exploitation potential
        
        # Check exploitation factors
        for factor, weight in self.exploitation_factors.items():
            if self._check_exploitation_factor(finding, factor):
                base_score *= weight
                analysis['factors'].append({
                    'type': 'exploitation',
                    'name': factor,
                    'weight': weight
                })
        
        analysis['score'] = min(1.0, base_score)
        return analysis
    
    def _analyze_cache_factors(self, finding: Dict) -> Dict:
        """
        Analyze cache-specific factors.
        
        Args:
            finding (dict): The finding to analyze.
            
        Returns:
            dict: Cache factor analysis results.
        """
        analysis = {
            'score': 0.0,
            'factors': []
        }
        
        base_score = 0.5  # Start with medium cache impact
        
        # Check cache-specific factors
        for factor, weight in self.cache_factors.items():
            if self._check_cache_factor(finding, factor):
                base_score *= weight
                analysis['factors'].append({
                    'type': 'cache',
                    'name': factor,
                    'weight': weight
                })
        
        analysis['score'] = min(1.0, base_score)
        return analysis
    
    def _calculate_overall_score(self, classification: Dict) -> Dict:
        """
        Calculate overall vulnerability score and severity.
        
        Args:
            classification (dict): Current classification results.
            
        Returns:
            dict: Overall score and severity.
        """
        result = {
            'overall_score': 0.0,
            'severity': 'low',
            'confidence': 0.0
        }
        
        # Weight the different scores
        weights = {
            'impact': 0.4,
            'exploitation': 0.3,
            'cache': 0.3
        }
        
        overall_score = (
            classification['impact_score'] * weights['impact'] +
            classification['exploitation_score'] * weights['exploitation'] +
            classification['cache_score'] * weights['cache']
        )
        
        result['overall_score'] = overall_score
        
        # Determine severity
        for level, threshold in sorted(
            self.severity_thresholds.items(),
            key=lambda x: x[1],
            reverse=True
        ):
            if overall_score >= threshold:
                result['severity'] = level
                break
        
        # Calculate confidence based on number and weight of factors
        factors = classification['factors']
        if factors:
            confidence_score = sum(f.get('weight', 1.0) for f in factors) / len(factors)
            result['confidence'] = min(1.0, confidence_score)
        
        return result
    
    def _generate_recommendations(self, classification: Dict, finding: Dict) -> List[Dict]:
        """
        Generate security recommendations based on classification.
        
        Args:
            classification (dict): Classification results.
            finding (dict): Original finding.
            
        Returns:
            list: Security recommendations.
        """
        recommendations = []
        
        # Add type-specific recommendations
        vuln_type = classification['type']
        if vuln_type == 'stored_xss':
            recommendations.extend([
                {
                    'priority': 'high',
                    'category': 'cache',
                    'description': 'Implement proper cache validation mechanisms',
                    'details': 'Ensure cached content is properly validated and sanitized before storage'
                },
                {
                    'priority': 'high',
                    'category': 'headers',
                    'description': 'Set appropriate cache control headers',
                    'details': 'Use Cache-Control: private for sensitive content'
                }
            ])
        
        elif vuln_type == 'cache_poisoning':
            recommendations.extend([
                {
                    'priority': 'critical',
                    'category': 'cache',
                    'description': 'Implement cache key validation',
                    'details': 'Validate and sanitize cache keys to prevent poisoning'
                },
                {
                    'priority': 'high',
                    'category': 'headers',
                    'description': 'Review cache variation headers',
                    'details': 'Ensure Vary headers are properly set for cached content'
                }
            ])
        
        # Add general security recommendations
        recommendations.extend([
            {
                'priority': 'high',
                'category': 'input',
                'description': 'Implement input validation',
                'details': 'Validate and sanitize all user input before processing'
            },
            {
                'priority': 'high',
                'category': 'output',
                'description': 'Implement output encoding',
                'details': 'Properly encode output based on the context'
            }
        ])
        
        # Add cache-specific recommendations if cache score is high
        if classification['cache_score'] > 0.6:
            recommendations.extend([
                {
                    'priority': 'high',
                    'category': 'cache',
                    'description': 'Review cache configuration',
                    'details': 'Ensure cache settings align with security requirements'
                },
                {
                    'priority': 'medium',
                    'category': 'monitoring',
                    'description': 'Implement cache monitoring',
                    'details': 'Monitor cache behavior for suspicious patterns'
                }
            ])
        
        return recommendations
    
    def _has_cache_persistence(self, finding: Dict) -> bool:
        """Check if vulnerability shows cache persistence."""
        cache_info = finding.get('cache_info', {})
        return bool(cache_info.get('persistence', False))
    
    def _is_cache_poisoning(self, finding: Dict) -> bool:
        """Check if vulnerability indicates cache poisoning."""
        cache_info = finding.get('cache_info', {})
        return bool(cache_info.get('poisoning_indicators', False))
    
    def _is_dom_based(self, finding: Dict) -> bool:
        """Check if vulnerability is DOM-based."""
        return bool(finding.get('dom_based', False))
    
    def _check_impact_factor(self, finding: Dict, factor: str) -> bool:
        """Check if an impact factor applies to the finding."""
        impact_info = finding.get('impact', {})
        return bool(impact_info.get(factor, False))
    
    def _check_exploitation_factor(self, finding: Dict, factor: str) -> bool:
        """Check if an exploitation factor applies to the finding."""
        exploitation_info = finding.get('exploitation', {})
        return bool(exploitation_info.get(factor, False))
    
    def _check_cache_factor(self, finding: Dict, factor: str) -> bool:
        """Check if a cache factor applies to the finding."""
        cache_info = finding.get('cache_info', {})
        return bool(cache_info.get(factor, False))
    
    def _analyze_group_patterns(self, findings: List[Dict]) -> Dict:
        """
        Analyze patterns across a group of findings.
        
        Args:
            findings (list): Group of findings to analyze.
            
        Returns:
            dict: Group pattern analysis.
        """
        analysis = {
            'total_findings': len(findings),
            'vulnerability_types': {},
            'common_factors': set(),
            'cache_patterns': {}
        }
        
        if not findings:
            return analysis
        
        # Count vulnerability types
        for finding in findings:
            vuln_type = finding.get('type', 'unknown')
            analysis['vulnerability_types'][vuln_type] = \
                analysis['vulnerability_types'].get(vuln_type, 0) + 1
        
        # Find common factors
        if findings:
            factors = set(findings[0].get('factors', []))
            for finding in findings[1:]:
                factors &= set(finding.get('factors', []))
            analysis['common_factors'] = factors
        
        # Analyze cache patterns
        cache_hits = 0
        cache_misses = 0
        for finding in findings:
            cache_info = finding.get('cache_info', {})
            if cache_info.get('is_hit'):
                cache_hits += 1
            else:
                cache_misses += 1
        
        analysis['cache_patterns'] = {
            'hits': cache_hits,
            'misses': cache_misses,
            'hit_rate': cache_hits / len(findings) if findings else 0
        }
        
        return analysis
